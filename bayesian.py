import matplotlib.pyplot as plt
import numpy as np

class Bandit:
    def __init__(self, p):
        self.p = p          # being the win-rate 
        self.a = 1          # alpha-value for beta-distribution
        self.b = 1          # beta-value for beta-distribution
        self.N = 0          # how often did wie play this bandit

    def pull(self):
        # returns True (1) with the probability of p, meaning we won this time pulling the bandit's arm
        return np.random.random() < self.p

    def update(self, x):
        # update our knowledge about the bandit, when we played it
        # x is the result of playing (pulling) the bandit, so either 1 (True/Win) or 0 (False/Loss)
        self.N += 1         # we played one more time
        self.a += x         # when we "won" on the last pull, we increase alpha
        self.b += 1 - x     # when we "lost" on the last pull, we increase beta

    def sample(self):
        # return a sample using the beta-distribution with current alpha and beta values of the bandit
        return np.random.beta(self.a, self.b)

def run_experiment(bandit_probs, num_trials, plot = False):
    # to run the experiment, we expect to have a list of win-probabilities for the bandits to create
    # and we need to know how long our experiment is (num_trials)

    # creating the bandits
    bandits = [Bandit(prob) for prob in bandit_probs]

    # keep track of some statistics
    rewards = np.zeros(num_trials)  # track in which attempts/trials we actually won

    for i in range(num_trials):
        # we choose the "best" bandit based on the best highest sample drawn from each bandits
        bandit_to_play = np.argmax([bandit.sample() for bandit in bandits])

        # pull the arm of the selected bandit
        reward = bandits[bandit_to_play].pull()

        # keep track of the rewards received
        rewards[i] = reward

        # update our knowledge about the bandit
        bandits[bandit_to_play].update(reward)
    
    # print our final knowledge (based on a sample) about the bandits and how often we played them
    #for bandit in bandits:
    #    print("Bandit win-rate: ", bandit.sample(), " - Bandit played:", bandit.N)

    cum_results = np.cumsum(rewards)
    win_rates = cum_results / (np.arange(num_trials) + 1)

    if plot:
        print("Win-Rate: ", win_rates[num_trials-1])
        plt.plot(win_rates)                                     # plot the realized win-rate
        plt.plot(np.ones(num_trials)*np.max(bandit_probs))      # have a straight line for the optimal win-rate
        plt.show()
    
    return (win_rates, bandits[np.argmax([bandit.p for bandit in bandits])].N)

if __name__ == "__main__":
    probs = [0.2, 0.4, 0.5, 0.75, 0.8]
    num_trials = 10000
    run_experiment(probs, num_trials, True)